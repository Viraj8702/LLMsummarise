{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the chunksize and temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This document is a technical advisory issued by a group in Wales concerning non-pharmaceutical interventions (NPIs) before Christmas. It highlights:\n",
      "\n",
      "**Key points:**\n",
      "\n",
      "* **Virus Transmission:** Infection spreads through contact between infected and uninfected individuals. Close contact, particularly indoors, poses higher risk. \n",
      "* **NPI Effectiveness:** Social distancing and quarantine remain effective in reducing transmission if adhered to correctly. Pre-isolating for ten days (avoiding mixing outside one's household) can significantly lower infection risk. Self-isolation is crucial for those experiencing COVID symptoms.\n",
      "\n",
      "* **Protection of Elderly:** Avoiding contact with vulnerable older family members is essential, even if motives are well-intentioned.\n",
      "* **Household Mixing Concerns:** Data shows increased household mixing, often coupled with misunderstanding the transmission risks. Limiting mixing between households significantly reduces overall risk of infection, hospitalization, and death.\n",
      "\n",
      "* **Modeling & Impact:** Policy modeling demonstrates that keeping the reproduction number (Rt) lower through reduced social interaction would drastically reduce deaths and NHS pressure. Imposing Tier 3-level restrictions before Christmas relaxation is recommended to minimize hospital bed requirements and fatalities.\n",
      "* **Current Situation:** While a recent decrease in test positivity after the firebreak period was observed, the trend is reversing with increasing case numbers in many areas. Local authorities Blaenau Gwent and Torfaen are experiencing particularly high rates, approaching pre-firebreak peak levels.\n",
      "\n",
      "\n",
      "**Overall, the document strongly advocates for continued NPIs and public vigilance to combat rising COVID-19 infections before Christmas.**\n",
      "\n",
      "\n",
      "Wales is currently experiencing a very high surge in COVID-19 cases with most areas classified as \"very high\" or \"high\" risk based on case rates per 100,000 people.  \n",
      "\n",
      "**Key Points:**\n",
      "\n",
      "* **High Transmission:** Case numbers are over 200 per 100,000 across almost all local authorities in Wales, particularly in urban areas. This is fueled by increased intergenerational mixing, including care home outbreaks and holiday gatherings.\n",
      "* **Rising Hospitalizations & Deaths:** The current Rt (reproduction number) suggests hospital admissions and deaths may rise over the next 2-3 weeks. Currently, death rates are comparable to May, with Wales experiencing higher excess deaths than England and Scotland.\n",
      "* **Winter Holidays & Increased Risk:**  The upcoming Christmas holidays are expected to significantly increase transmission due to heightened social gatherings and extended household mixing. This could lead to more people isolating or quarantining over the holiday period.\n",
      "* **Limitations of Lateral Flow Tests:** While new rapid testing technologies can aid in identifying infections quicker, they lack the accuracy of RT-PCR tests, which are still considered the primary method for diagnosis.\n",
      "\n",
      "**Overall Message:** Wales is facing a serious COVID-19 surge, and public health officials are urging caution during the festive season to prevent further transmission and potential strain on NHS resources. Measures like social distancing and quarantining remain crucial in mitigating the spread of infection. \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "This text outlines risk mitigation strategies for socializing during the Christmas period amidst ongoing COVID-19 concerns.  \n",
      "\n",
      "**Key takeaways:**\n",
      "\n",
      "* **Pre-isolation is crucial:** Spending 10 days (one incubation period) separated from others before gatherings significantly reduces infection risk. This applies to everyone, especially those visiting older relatives or working in high-risk occupations.\n",
      "* **Postponing Christmas celebrations or meeting remotely is advised.** This minimizes exposure risk.\n",
      "* **Strict hygiene practices are essential:** Handwashing and ventilation during visits can further limit transmission.\n",
      "* **Alcohol's influence on judgment and inhibitions increases the likelihood of risky behavior, making social distancing harder to maintain.**\n",
      "* **Transmission often occurs through prolonged contact with familiar people in a home setting, even without symptoms.** \n",
      "\n",
      "The text emphasizes that widespread vaccination will eventually alleviate current restrictions. Until then, following these guidelines is crucial to protect vulnerable individuals and slow down virus spread during the holiday season. The cited SAGE papers and reports provide further details on risk assessment and mitigation strategies for various settings like hospitality and entertainment.\n",
      "\n",
      "\n",
      "Overall,  the message is clear: while festive gatherings remain important, responsible precautions are necessary to navigate the risks associated with COVID-19 transmission during Christmas. \n",
      "\n",
      "\n",
      "\n",
      "The text presents evidence linking certain activities and settings with increased risk of COVID-19 infection. \n",
      "\n",
      "**Key findings:**\n",
      "\n",
      "* **Dining out and socializing:** Individuals infected with SARS-CoV-2 were significantly more likely to report dining at restaurants (2.8x more likely) or visiting bars/coffee shops (3.9x more likely) compared to uninfected controls.\n",
      "* **Occupations:** Research suggests higher COVID-19 infection rates among workers in warehouse settings, construction, hospitality, and health & social care. \n",
      "* **Entertainment:** Engaging in entertainment activities is shown to be associated with increased odds of disease.\n",
      "\n",
      "**Data sources and limitations:**\n",
      "\n",
      "The text cites various data sources like:\n",
      "\n",
      "* US CDC studies\n",
      "* Public Health England epidemiological investigations\n",
      "* Test, Trace and Protect (TTP) system reports\n",
      "* Local Authority cluster data\n",
      "\n",
      "However, it acknowledges the limitations of relying on recall-based data from TTP interviews and emphasizes that these findings should not be solely used to establish definitive cause-and-effect relationships. \n",
      "\n",
      "**Schools and Education:** The text notes an increasing number of cases and contacts within schools and suggests a possible link between school reopening and higher infection rates in the wider population, though a clear causal relationship remains unclear.\n",
      "\n",
      "\n",
      "**Overall:**\n",
      "\n",
      "The information presented highlights the potential risks associated with certain activities and settings during the COVID-19 pandemic. While more accurate data collection is needed for definitive conclusions, the evidence suggests that ongoing precautions and public health measures are crucial to mitigate the spread of infection.\n",
      "\n",
      "\n",
      "This document discusses the complex issue of school closures during a pandemic, weighing the risks of transmission against the potential harms to children's well-being and education.\n",
      "\n",
      "**Key points:**\n",
      "\n",
      "* **School closures should be a last resort** due to their negative impact on children's physical and mental health, learning, and social development.\n",
      "* **Open schools increase mobility**, which can contribute to virus transmission. However, closing schools too late in an outbreak may be less effective.\n",
      "* **The Christmas period presents a unique challenge**. Extended family gatherings (Christmas bubbles) increase the risk of intergenerational transmission.  \n",
      "\n",
      "**Possible mitigation strategies:**\n",
      "\n",
      "* **Pre-isolation for families with children**: Reducing social mixing before Christmas.\n",
      "* **Blended learning models**: Offering some teaching remotely to reduce in-person interactions. \n",
      "* **Limited-capacity \"hub schools\"**: Providing care and education for essential workers' and vulnerable children's needs.\n",
      "* **Shortened holidays**: Utilizing extra school weeks for learning.\n",
      "\n",
      "**Challenges:**\n",
      "\n",
      "* Mitigations like online learning can exacerbate inequalities faced by lower socioeconomic groups.\n",
      "* Balancing the risks and benefits of closures requires careful consideration and evidence-based decision making.\n",
      "\n",
      "**Ethical Considerations:**\n",
      "\n",
      "* The document emphasizes shared responsibility for behavior change and acknowledges that not everyone adheres to guidelines, potentially further complicating the situation.\n",
      "\n",
      "\n",
      "Ultimately, the document highlights the need for a nuanced approach to school closures, taking into account a variety of factors and prioritizing the well-being of children while also mitigating the spread of disease. \n",
      "\n",
      "\n",
      "\n",
      "This text analyzes public behavior related to COVID-19 in Wales, emphasizing the shift from firebreak restrictions.  While adherence to guidelines remains high overall, several factors influence compliance:\n",
      "\n",
      "* **Barriers**: Understanding guidelines, lacking skills like saying \"no,\" and insufficient access to support (financial, practical, emotional).\n",
      "* **Disagreement**: Despite strong confidence in Welsh Government, some individuals disagree with the implemented restrictions and are less likely to follow them.\n",
      "* **Mixing and Risk Perception**: Survey data suggests mixing within the home exceeds guidelines, with a misunderstanding regarding transmission risks - people perceive strangers as bigger risks than friends/family.\n",
      "\n",
      "The text highlights potential risks exacerbating community transmission:\n",
      "\n",
      "* Relaxed behaviors post-firebreak.\n",
      "* Increased mingling in hospitality and retail before Christmas.\n",
      "* Possible complacency due to vaccine announcements.\n",
      "\n",
      "Despite these challenges, the document reiterates the importance of evidence-informed approaches based on:\n",
      "\n",
      "* **Public communication**: Clear, simple risk messaging with rationale, especially if regional variations exist.\n",
      "* **Support systems**: Continued financial aid (e.g., self-isolation payments) and encouragement of social & emotional support networks.\n",
      "\n",
      "* **Tailored Communication**: Utilizing appropriate channels reflecting demographic and cultural nuances and engaging in co-production with communities.\n",
      "\n",
      "\n",
      "The document concludes by stressing that enforcement should be a last resort, prioritizing engagement, explanation, and encouragement efforts while remaining aware of potential inequities in application. \n",
      "\n",
      "\n",
      "\n",
      "This document outlines recommendations for managing COVID-19 risk during the festive season.  \n",
      "\n",
      "**Key Points:**\n",
      "\n",
      "* **Early intervention is crucial**: Waiting until cases are high can lead to runaway outbreaks and require more severe lockdowns later on.\n",
      "* **Short, sharp bursts of restrictions work better:** Prolonged restrictions lead to reduced adherence and effectiveness over time. \n",
      "* **Community transmission levels matter:** Higher levels in the community spread to other vulnerable environments like hospitals, care homes, and prisons.  \n",
      "* **Modeling suggests clear benefits of stronger pre-Christmas measures:** Tier 2 or 3 restrictions before Christmas can significantly reduce deaths, NHS strain, and ICU bed usage during the winter months.\n",
      "* **Social mixing over Christmas will likely increase transmission:** This is expected to result in a further 10% increase in spread compared to usual levels.\n",
      "\n",
      "**To summarize**: The document emphasizes that proactive measures, like Tier 2 or 3 restrictions leading up to Christmas, are essential to minimize the impact of COVID-19 during the festive season. They highlight the effectiveness of short, sharp interventions and stress the dangers of high community transmission levels.\n",
      "\n",
      "\n",
      "The document further explains the methodology used in a Swansea University study that models various policy options (described in more detail in attached documents). This model illustrates the potential benefits of different levels of restriction, based on real-world data and projections.  \n",
      "\n",
      "\n",
      "\n",
      "This text presents modeling outcomes from Swansea University regarding the potential impact of various Christmas policy interventions on COVID-19 infection rates and healthcare system strain. \n",
      "\n",
      "**Key Takeaways:**\n",
      "\n",
      "* **Increased Transmission During Christmas:** The models account for potential increased mixing during the Christmas period, estimating an additional 10% transmission.\n",
      "* **Scenario Comparisons:** Different scenarios are modeled based on varying levels of intervention (\"No Intervention,\" \"Tier 2,\" and \"Tier 3\" restrictions) and assumed background R values (1.3 to 1.4).\n",
      "* **Impact on Healthcare System:** The most concerning scenario (\"No Intervention\" with an R value of 1.4) projects substantial pressure on healthcare systems:\n",
      "    * **Hospital Bed Occupancy:** Up to 8,570 beds needed for COVID-19 patients.\n",
      "    * **ICU Capacity:**  Up to 1,030 ICU beds required.\n",
      "    * **Fatalities:** An estimated 2,520 deaths.\n",
      "\n",
      "* **Effectiveness of Interventions:** Stronger restrictions (Tier 3) are shown to significantly reduce hospital admissions, ICU occupancy, and deaths compared to less restrictive scenarios.\n",
      "\n",
      "\n",
      "The figures accompanying the text (Figure 1-4) visually represent these scenario comparisons across time and key metrics like deaths per day, ICU occupancy, and hospital bed demand.\n",
      "\n",
      "**Overall Message:**  The modeling emphasizes that strong interventions like \"Tier 3\" restrictions are crucial to mitigate the surge in COVID-19 cases and prevent overwhelming healthcare systems during the Christmas period.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "\n",
    "\n",
    "# Initialize the OpenAI client\n",
    "client = OpenAI(\n",
    "    base_url='http://localhost:11434/v1/',\n",
    "    api_key='ollama',  # Placeholder, required by the client but not used\n",
    ")\n",
    "# chunking each file text\n",
    "def chunktext(text, chunk_size=3500, overlap=150):\n",
    "    chunks = []\n",
    "    start = 0\n",
    "    while start < len(text):\n",
    "        end = min(start + chunk_size, len(text))\n",
    "        # the last sentence should end with . or ? or !\n",
    "        if end < len(text):\n",
    "            while end > start and text[end] not in '.!?':\n",
    "                end -= 1\n",
    "        chunks.append(text[start:end])\n",
    "        # what should be the next starting point after chunk 1 is passed\n",
    "        # to continue, it should find the word where it cuts off and overlap by 500 so that it will lookup for previous 500 words cut from the specific word\n",
    "        start += chunk_size - overlap\n",
    "    return chunks\n",
    "\n",
    "def getsummary(content):\n",
    "    response = client.chat.completions.create(\n",
    "        model='gemma2',\n",
    "        messages=[\n",
    "            {\n",
    "                'role': 'user',\n",
    "                'content': f'Please provide a summary of the following text:\\n\\n{content}',\n",
    "            }\n",
    "        ],\n",
    "        max_tokens=1500,  # Number of tokens for the summary\n",
    "        temperature=0.5,  # Temperature controls the creativity of the response\n",
    "    )\n",
    "    return response.choices[0].message.content+\"\\n\\n\"\n",
    "\n",
    "def summarizetext(filepath):\n",
    "    # reading the file\n",
    "    with open(filepath, 'r', encoding='utf-8') as file:\n",
    "        content = file.read()\n",
    "\n",
    "    chunks = chunktext(content)\n",
    "    \n",
    "    summaries = []\n",
    "    # collecting the summary\n",
    "    for chunk in chunks:\n",
    "        summary = getsummary(chunk)\n",
    "        summaries.append(summary)\n",
    "    \n",
    "    finalsummary = \"\\n\".join(summaries)\n",
    "    return finalsummary\n",
    "\n",
    "\n",
    "filepath = '../2.PDFExtraction/PYPDF2/PYPDF2textclean/INQ000350057.txt'\n",
    "\n",
    "summary = summarizetext(filepath)\n",
    "\n",
    "print(summary)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Llama3 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am LLaMA, a large language model trained by Meta AI that can converse with humans in a natural and engaging way. I'm not a specific person or character, but rather a computer program designed to simulate conversation. My purpose is to assist users by providing helpful and accurate information, answering questions, and even generating creative content like stories and poems.\n"
     ]
    }
   ],
   "source": [
    "# checking if the model is responding\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "    base_url='http://localhost:11434/v1/',\n",
    "\n",
    "    # required but ignored\n",
    "    api_key='ollama',\n",
    ")\n",
    "\n",
    "chat_completion = client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\n",
    "            'role': 'user',\n",
    "            'content': 'Which model are you?',\n",
    "        }\n",
    "    ],\n",
    "    model='llama3',\n",
    ")\n",
    "\n",
    "print(chat_completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary for INQ000350057.txt\n",
      "Summary for INQ000350094.txt\n",
      "Summary for INQ000350513.txt\n",
      "Summary for INQ000350691.txt\n",
      "Summary for INQ000383581.txt\n",
      "Summary for INQ000383585.txt\n",
      "Summary for INQ000383998.txt\n",
      "Summary for INQ000385719.txt\n",
      "Summary for INQ000395589.txt\n",
      "Summary for INQ000395913.txt\n",
      "Summary for INQ000396684.txt\n",
      "Summary for INQ000396685.txt\n",
      "Summary for INQ000396686.txt\n",
      "Summary for INQ000400585.txt\n",
      "Summary for INQ000412042.txt\n",
      "Summaries have been saved successfully.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "    base_url='http://localhost:11434/v1/',\n",
    "    api_key='ollama',  \n",
    ")\n",
    "# chunking each file text\n",
    "def chunktext(text, chunk_size=3500, overlap=150):\n",
    "    chunks = []\n",
    "    start = 0\n",
    "    while start < len(text):\n",
    "        end = min(start + chunk_size, len(text))\n",
    "        # the last sentence should end with . or ? or !\n",
    "        if end < len(text):\n",
    "            while end > start and text[end] not in '.!?':\n",
    "                end -= 1\n",
    "        chunks.append(text[start:end])\n",
    "        # what should be the next starting point after chunk 1 is passed\n",
    "        # to continue, it should find the word where it cuts off and overlap by 150 so that it will lookup for previous 150 words cut from the specific word\n",
    "        start += chunk_size - overlap\n",
    "    return chunks\n",
    "\n",
    "def getsummary(content):\n",
    "    response = client.chat.completions.create(\n",
    "        model='llama3',\n",
    "        messages=[\n",
    "            {\n",
    "                'role': 'user',\n",
    "                'content': f'Please provide a summary of the following text:\\n\\n{content}',\n",
    "            }\n",
    "        ],\n",
    "        max_tokens=1500,  # number of tokens for the summary\n",
    "        temperature=0.5,  # temperature controls the creativity of the response\n",
    "    )\n",
    "    return response.choices[0].message.content+\"\\n\\n\"\n",
    "\n",
    "def summarizetext(filepath):\n",
    "    # reading the file\n",
    "    with open(filepath, 'r', encoding='utf-8') as file:\n",
    "        content = file.read()\n",
    "\n",
    "    chunks = chunktext(content)\n",
    "    \n",
    "    summaries = []\n",
    "    # collecting the summary\n",
    "    for chunk in chunks:\n",
    "        summary = getsummary(chunk)\n",
    "        summaries.append(summary)\n",
    "    \n",
    "    # returning each chunks to file\n",
    "    finalsummary = \"\\n\".join(summaries)\n",
    "    return finalsummary\n",
    "\n",
    "# input directory for reading the cleaned text file \n",
    "inputfiles = '../2.PDFExtraction/PYPDF2/PYPDF2textclean/'\n",
    "# output directory to store the summary of each files\n",
    "outputpath = 'LLM Summaries/Selected_LLM_Models_PYPDF2/llama3/lamma3res/'\n",
    "\n",
    "os.makedirs(outputpath, exist_ok=True)\n",
    "\n",
    "for filename in os.listdir(inputfiles):\n",
    "    if filename.endswith('.txt'):\n",
    "        filepath = os.path.join(inputfiles, filename)\n",
    "        \n",
    "        # read and summarize the text content\n",
    "        summary = summarizetext(filepath)\n",
    "        \n",
    "        # write the summary to the output directory\n",
    "        outputfilepath = os.path.join(outputpath, f\"{os.path.splitext(filename)[0]}.txt\")\n",
    "        with open(outputfilepath, 'w', encoding='utf-8') as outputfile:\n",
    "            outputfile.write(summary)\n",
    "        \n",
    "        print(f\"Summary for {filename}\")\n",
    "\n",
    "print(\"Summaries have been saved successfully.\")\n",
    "\n",
    "# rough estimation of 77 minutes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Adding title to each files__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# reading the csv files that has the detials about the files\n",
    "df = pd.read_csv('../2.PDFExtraction/SamplePdfDetail.csv')\n",
    "\n",
    "txtdir = 'LLM Summaries/Selected_LLM_Models_PYPDF2/llama3/lamma3res/'\n",
    "\n",
    "outputdir = 'LLM Summaries/Selected_LLM_Models_PYPDF2/llama3/llama3final/'\n",
    "\n",
    "os.makedirs(outputdir, exist_ok=True)\n",
    "\n",
    "for filename in os.listdir(txtdir):\n",
    "    if filename.endswith('.txt'):\n",
    "        txtpath = os.path.join(txtdir, filename)\n",
    "        \n",
    "        # replacing the .txt extension with .pdf to match the CSV 'Filename' column\n",
    "        csvfilename = filename.replace('.txt', '.pdf')\n",
    "        \n",
    "        # if the CSV has a matching filename\n",
    "        rowsfound = df[df['Filename'] == csvfilename]\n",
    "        \n",
    "        if not rowsfound.empty:\n",
    "            # row which is appearing as the same filename\n",
    "            title = rowsfound.iloc[0]['Title']\n",
    "            \n",
    "            # obtaining the content of the txt file\n",
    "            with open(txtpath, 'r', encoding='utf-8') as file:\n",
    "                content = file.read()\n",
    "            \n",
    "            # output directory to store the response\n",
    "            outputpath = os.path.join(outputdir, filename)\n",
    "            \n",
    "            # writing the title for the each txt file\n",
    "            with open(outputpath, 'w', encoding='utf-8') as file:\n",
    "                file.write(f\"Title: {title}\\n\\n{content}\")\n",
    "        else:\n",
    "            print(f\"No matching CSV entry found for {filename}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Llama3.1 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm an artificial intelligence model known as Llama. Llama stands for \"Large Language Model Meta AI.\"\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "    base_url='http://localhost:11434/v1/',\n",
    "\n",
    "    # required but ignored\n",
    "    api_key='ollama',\n",
    ")\n",
    "\n",
    "chat_completion = client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\n",
    "            'role': 'user',\n",
    "            'content': 'Which model are you?',\n",
    "        }\n",
    "    ],\n",
    "    model='llama3.1',\n",
    ")\n",
    "\n",
    "print(chat_completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__All the files to be passed for summarisation__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary for INQ000350057.txt\n",
      "Summary for INQ000350094.txt\n",
      "Summary for INQ000350513.txt\n",
      "Summary for INQ000350691.txt\n",
      "Summary for INQ000383581.txt\n",
      "Summary for INQ000383585.txt\n",
      "Summary for INQ000383998.txt\n",
      "Summary for INQ000385719.txt\n",
      "Summary for INQ000395589.txt\n",
      "Summary for INQ000395913.txt\n",
      "Summary for INQ000396684.txt\n",
      "Summary for INQ000396685.txt\n",
      "Summary for INQ000396686.txt\n",
      "Summary for INQ000400585.txt\n",
      "Summary for INQ000412042.txt\n",
      "Summaries have been saved successfully.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "\n",
    "\n",
    "client = OpenAI(\n",
    "    base_url='http://localhost:11434/v1/',\n",
    "    api_key='ollama',  # Placeholder, required by the client but not used\n",
    ")\n",
    "\n",
    "# chunking each file text\n",
    "def chunktext(text, chunk_size=3500, overlap=150):\n",
    "    chunks = []\n",
    "    start = 0\n",
    "    while start < len(text):\n",
    "        end = min(start + chunk_size, len(text))\n",
    "        # the last sentence should end with . or ? or !\n",
    "        if end < len(text):\n",
    "            while end > start and text[end] not in '.!?':\n",
    "                end -= 1\n",
    "        chunks.append(text[start:end])\n",
    "        # what should be the next starting point after chunk 1 is passed\n",
    "        # to continue, it should find the word where it cuts off and overlap by 500 so that it will lookup for previous 500 words cut from the specific word\n",
    "        start += chunk_size - overlap\n",
    "    return chunks\n",
    "\n",
    "def getsummary(content):\n",
    "    response = client.chat.completions.create(\n",
    "        model='llama3.1',\n",
    "        messages=[\n",
    "            {\n",
    "                'role': 'user',\n",
    "                'content': f'Please provide a summary of the following text:\\n\\n{content}',\n",
    "            }\n",
    "        ],\n",
    "        max_tokens=1500,  # number of tokens for the summary\n",
    "        temperature=0.5,  # temperature controls the creativity of the response\n",
    "    )\n",
    "    return response.choices[0].message.content+\"\\n\\n\"\n",
    "\n",
    "def summarizetext(filepath):\n",
    "    # reading the file\n",
    "    with open(filepath, 'r', encoding='utf-8') as file:\n",
    "        content = file.read()\n",
    "\n",
    "    chunks = chunktext(content)\n",
    "    \n",
    "    summaries = []\n",
    "    # collecting the summary\n",
    "    for chunk in chunks:\n",
    "        summary = getsummary(chunk)\n",
    "        summaries.append(summary)\n",
    "    \n",
    "    finalsummary = \"\\n\".join(summaries)\n",
    "    return finalsummary\n",
    "\n",
    "# input directory for reading the cleaned text file\n",
    "inputfiles = '../2.PDFExtraction/PYPDF2/PYPDF2textclean/'\n",
    "# output directory to store the summary of each files\n",
    "outputpath = 'LLM Summaries/Selected_LLM_Models_PYPDF2/llama3.1/llama3.1res/'\n",
    "\n",
    "os.makedirs(outputpath, exist_ok=True)\n",
    "\n",
    "for filename in os.listdir(inputfiles):\n",
    "    if filename.endswith('.txt'):\n",
    "        filepath = os.path.join(inputfiles, filename)\n",
    "        \n",
    "        # read and summarize the text content\n",
    "        summary = summarizetext(filepath)\n",
    "        \n",
    "        # write the summary to the output directory\n",
    "        outputfilepath = os.path.join(outputpath, f\"{os.path.splitext(filename)[0]}.txt\")\n",
    "        with open(outputfilepath, 'w', encoding='utf-8') as outputfile:\n",
    "            outputfile.write(summary)\n",
    "        \n",
    "        print(f\"Summary for {filename}\")\n",
    "\n",
    "print(\"Summaries have been saved successfully.\")\n",
    "\n",
    "# rough estimation of 82 minutes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Adding the titles to each responses__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "\n",
    "df = pd.read_csv('../2.PDFExtraction/SamplePdfDetail.csv')\n",
    "\n",
    "txtdir = 'LLM Summaries/Selected_LLM_Models_PYPDF2/llama3.1/llama3.1res/'\n",
    "\n",
    "ouputdir = 'LLM Summaries/Selected_LLM_Models_PYPDF2/llama3.1/llama3.1final/'\n",
    "\n",
    "os.makedirs(ouputdir, exist_ok=True)\n",
    "\n",
    "for filename in os.listdir(txtdir):\n",
    "    if filename.endswith('.txt'):\n",
    "        txtpath = os.path.join(txtdir, filename)\n",
    "        \n",
    "        # replacing the .txt extension with .pdf to match the CSV 'Filename' column\n",
    "        csvfilename = filename.replace('.txt', '.pdf')\n",
    "        \n",
    "        # if the CSV has a matching filename\n",
    "        rowsfound = df[df['Filename'] == csvfilename]\n",
    "        \n",
    "        if not rowsfound.empty:\n",
    "            # row which is appearing as the same filename\n",
    "            title = rowsfound.iloc[0]['Title']\n",
    "            \n",
    "            # obtaining the content of the txt file\n",
    "            with open(txtpath, 'r', encoding='utf-8') as file:\n",
    "                content = file.read()\n",
    "            \n",
    "            # output directory to store the response\n",
    "            outputpath = os.path.join(ouputdir, filename)\n",
    "            \n",
    "            # writing the title for the each txt file\n",
    "            with open(outputpath, 'w', encoding='utf-8') as file:\n",
    "                file.write(f\"Title: {title}\\n\\n{content}\")\n",
    "        else:\n",
    "            print(f\"No matching CSV entry found for {filename}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gemma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am a large language model, trained by Google. I am designed to assist and engage in meaningful conversations with users.\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "# running on local machine\n",
    "client = OpenAI(\n",
    "    base_url='http://localhost:11434/v1/',\n",
    "\n",
    "    api_key='ollama',\n",
    ")\n",
    "\n",
    "chat_completion = client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\n",
    "            'role': 'user',\n",
    "            'content': 'Which model are you?',\n",
    "        }\n",
    "    ],\n",
    "    model='gemma',\n",
    ")\n",
    "\n",
    "print(chat_completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__All the files to be passed for summarisation__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary for INQ000350057.txt\n",
      "Summary for INQ000350094.txt\n",
      "Summary for INQ000350513.txt\n",
      "Summary for INQ000350691.txt\n",
      "Summary for INQ000383581.txt\n",
      "Summary for INQ000383585.txt\n",
      "Summary for INQ000383998.txt\n",
      "Summary for INQ000385719.txt\n",
      "Summary for INQ000395589.txt\n",
      "Summary for INQ000395913.txt\n",
      "Summary for INQ000396684.txt\n",
      "Summary for INQ000396685.txt\n",
      "Summary for INQ000396686.txt\n",
      "Summary for INQ000400585.txt\n",
      "Summary for INQ000412042.txt\n",
      "Summaries have been saved successfully.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "    base_url='http://localhost:11434/v1/',\n",
    "    api_key='ollama',  # Placeholder, required by the client but not used\n",
    ")\n",
    "\n",
    "# chunking each file text\n",
    "def chunktext(text, chunk_size=3500, overlap=150):\n",
    "    chunks = []\n",
    "    start = 0\n",
    "    while start < len(text):\n",
    "        end = min(start + chunk_size, len(text))\n",
    "        # the last sentence should end with . or ? or !\n",
    "        if end < len(text):\n",
    "            while end > start and text[end] not in '.!?':\n",
    "                end -= 1\n",
    "        chunks.append(text[start:end])\n",
    "        # what should be the next starting point after chunk 1 is passed\n",
    "        # to continue, it should find the word where it cuts off and overlap by 500 so that it will lookup for previous 500 words cut from the specific word\n",
    "        start += chunk_size - overlap\n",
    "    return chunks\n",
    "\n",
    "def getsummary(content):\n",
    "    response = client.chat.completions.create(\n",
    "        model='gemma',\n",
    "        messages=[\n",
    "            {\n",
    "                'role': 'user',\n",
    "                'content': f'Please provide a summary of the following text:\\n\\n{content}',\n",
    "            }\n",
    "        ],\n",
    "        max_tokens=1500,  # Number of tokens for the summary\n",
    "        temperature=0.5,  # Temperature controls the creativity of the response\n",
    "    )\n",
    "    return response.choices[0].message.content+\"\\n\\n\"\n",
    "\n",
    "def summarizetext(filepath):\n",
    "    # reading the file\n",
    "    with open(filepath, 'r', encoding='utf-8') as file:\n",
    "        content = file.read()\n",
    "\n",
    "    chunks = chunktext(content)\n",
    "    \n",
    "    summaries = []\n",
    "    # collecting the summary\n",
    "    for chunk in chunks:\n",
    "        summary = getsummary(chunk)\n",
    "        summaries.append(summary)\n",
    "    \n",
    "    finalsummary = \"\\n\".join(summaries)\n",
    "    return finalsummary\n",
    "\n",
    "# input directory for reading the cleaned text file \n",
    "inputfiles = '../2.PDFExtraction/PYPDF2/PYPDF2textclean/'\n",
    "# output directory to store the summary of each files\n",
    "outputpath = 'LLM Summaries/Selected_LLM_Models_PYPDF2/gemma/gemmares/'\n",
    "\n",
    "os.makedirs(outputpath, exist_ok=True)\n",
    "\n",
    "for filename in os.listdir(inputfiles):\n",
    "    if filename.endswith('.txt'):\n",
    "        filepath = os.path.join(inputfiles, filename)\n",
    "        \n",
    "        # read and summarize the text content\n",
    "        summary = summarizetext(filepath)\n",
    "        \n",
    "        # write the summary to the output directory\n",
    "        outputfilepath = os.path.join(outputpath, f\"{os.path.splitext(filename)[0]}.txt\")\n",
    "        with open(outputfilepath, 'w', encoding='utf-8') as outputfile:\n",
    "            outputfile.write(summary)\n",
    "        \n",
    "        print(f\"Summary for {filename}\")\n",
    "\n",
    "print(\"Summaries have been saved successfully.\")\n",
    "\n",
    "# rough estimation of 100 minutes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Adding titles to each response files__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "df = pd.read_csv('../2.PDFExtraction/SamplePdfDetail.csv')\n",
    "\n",
    "txtdir = 'LLM Summaries/Selected_LLM_Models_PYPDF2/gemma/gemmares/'\n",
    "\n",
    "ouputdir = 'LLM Summaries/Selected_LLM_Models_PYPDF2/gemma/gemmafinal/'\n",
    "\n",
    "os.makedirs(ouputdir, exist_ok=True)\n",
    "\n",
    "for filename in os.listdir(txtdir):\n",
    "    if filename.endswith('.txt'):\n",
    "        txtpath = os.path.join(txtdir, filename)\n",
    "        \n",
    "        # replacing the .txt extension with .pdf to match the CSV 'Filename' column\n",
    "        csvfilename = filename.replace('.txt', '.pdf')\n",
    "        \n",
    "        # if the CSV has a matching filename\n",
    "        rowsfound = df[df['Filename'] == csvfilename]\n",
    "        \n",
    "        if not rowsfound.empty:\n",
    "            # row which is appearing as the same filename\n",
    "            title = rowsfound.iloc[0]['Title']\n",
    "            \n",
    "            # obtaining the content of the txt file\n",
    "            with open(txtpath, 'r', encoding='utf-8') as file:\n",
    "                content = file.read()\n",
    "            \n",
    "            # output directory to store the response\n",
    "            outputpath = os.path.join(ouputdir, filename)\n",
    "            \n",
    "            # writing the title for the each txt file\n",
    "            with open(outputpath, 'w', encoding='utf-8') as file:\n",
    "                file.write(f\"Title: {title}\\n\\n{content}\")\n",
    "        else:\n",
    "            print(f\"No matching CSV entry found for {filename}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gemma 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am Gemma, an open-weights AI assistant.\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "    base_url='http://localhost:11434/v1/',\n",
    "\n",
    "    # required but ignored\n",
    "    api_key='ollama',\n",
    ")\n",
    "\n",
    "chat_completion = client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\n",
    "            'role': 'user',\n",
    "            'content': 'Which model are you?',\n",
    "        }\n",
    "    ],\n",
    "    model='gemma2',\n",
    ")\n",
    "\n",
    "print(chat_completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__All the files to be passed for summarisation__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary for INQ000350057.txt\n",
      "Summary for INQ000350094.txt\n",
      "Summary for INQ000350513.txt\n",
      "Summary for INQ000350691.txt\n",
      "Summary for INQ000383581.txt\n",
      "Summary for INQ000383585.txt\n",
      "Summary for INQ000383998.txt\n",
      "Summary for INQ000385719.txt\n",
      "Summary for INQ000395589.txt\n",
      "Summary for INQ000395913.txt\n",
      "Summary for INQ000396684.txt\n",
      "Summary for INQ000396685.txt\n",
      "Summary for INQ000396686.txt\n",
      "Summary for INQ000400585.txt\n",
      "Summary for INQ000412042.txt\n",
      "Summaries have been saved successfully.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "\n",
    "\n",
    "# Initialize the OpenAI client\n",
    "client = OpenAI(\n",
    "    base_url='http://localhost:11434/v1/',\n",
    "    api_key='ollama',  # Placeholder, required by the client but not used\n",
    ")\n",
    "# chunking each file text\n",
    "def chunktext(text, chunk_size=3500, overlap=150):\n",
    "    chunks = []\n",
    "    start = 0\n",
    "    while start < len(text):\n",
    "        end = min(start + chunk_size, len(text))\n",
    "        # the last sentence should end with . or ? or !\n",
    "        if end < len(text):\n",
    "            while end > start and text[end] not in '.!?':\n",
    "                end -= 1\n",
    "        chunks.append(text[start:end])\n",
    "        # what should be the next starting point after chunk 1 is passed\n",
    "        # to continue, it should find the word where it cuts off and overlap by 500 so that it will lookup for previous 500 words cut from the specific word\n",
    "        start += chunk_size - overlap\n",
    "    return chunks\n",
    "\n",
    "def getsummary(content):\n",
    "    response = client.chat.completions.create(\n",
    "        model='gemma2',\n",
    "        messages=[\n",
    "            {\n",
    "                'role': 'user',\n",
    "                'content': f'Please provide a summary of the following text:\\n\\n{content}',\n",
    "            }\n",
    "        ],\n",
    "        max_tokens=1500,  # Number of tokens for the summary\n",
    "        temperature=0.5,  # Temperature controls the creativity of the response\n",
    "    )\n",
    "    return response.choices[0].message.content+\"\\n\\n\"\n",
    "\n",
    "def summarizetext(filepath):\n",
    "    # reading the file\n",
    "    with open(filepath, 'r', encoding='utf-8') as file:\n",
    "        content = file.read()\n",
    "\n",
    "    chunks = chunktext(content)\n",
    "    \n",
    "    summaries = []\n",
    "    # collecting the summary\n",
    "    for chunk in chunks:\n",
    "        summary = getsummary(chunk)\n",
    "        summaries.append(summary)\n",
    "    \n",
    "    finalsummary = \"\\n\".join(summaries)\n",
    "    return finalsummary\n",
    "\n",
    "# input directory for reading the cleaned text file\n",
    "inputfiles = '../2.PDFExtraction/PYPDF2/PYPDF2textclean/'\n",
    "# output directory to store the summary of each files\n",
    "outputpath = 'LLM Summaries/Selected_LLM_Models_PYPDF2/gemma2/gemma2res/'\n",
    "\n",
    "os.makedirs(outputpath, exist_ok=True)\n",
    "\n",
    "for filename in os.listdir(inputfiles):\n",
    "    if filename.endswith('.txt'):\n",
    "        filepath = os.path.join(inputfiles, filename)\n",
    "        \n",
    "        # read and summarize the text content\n",
    "        summary = summarizetext(filepath)\n",
    "        \n",
    "        # write the summary to the output directory\n",
    "        outputfilepath = os.path.join(outputpath, f\"{os.path.splitext(filename)[0]}.txt\")\n",
    "        with open(outputfilepath, 'w', encoding='utf-8') as outputfile:\n",
    "            outputfile.write(summary)\n",
    "        \n",
    "        print(f\"Summary for {filename}\")\n",
    "\n",
    "print(\"Summaries have been saved successfully.\")\n",
    "\n",
    "# rough estimation of 155 minutes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Adding titles to reponses in separate directory__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "df = pd.read_csv('../2.PDFExtraction/SamplePdfDetail.csv')\n",
    "\n",
    "txtdir = 'LLM Summaries/Selected_LLM_Models_PYPDF2/gemma2/gemma2res/'\n",
    "\n",
    "ouputdir = 'LLM Summaries/Selected_LLM_Models_PYPDF2/gemma2/gemma2final/'\n",
    "\n",
    "os.makedirs(ouputdir, exist_ok=True)\n",
    "\n",
    "for filename in os.listdir(txtdir):\n",
    "    if filename.endswith('.txt'):\n",
    "        txtpath = os.path.join(txtdir, filename)\n",
    "        \n",
    "        # replacing the .txt extension with .pdf to match the CSV 'Filename' column\n",
    "        csvfilename = filename.replace('.txt', '.pdf')\n",
    "        \n",
    "        # if the CSV has a matching filename\n",
    "        rowsfound = df[df['Filename'] == csvfilename]\n",
    "        \n",
    "        if not rowsfound.empty:\n",
    "            # row which is appearing as the same filename\n",
    "            title = rowsfound.iloc[0]['Title']\n",
    "            \n",
    "            # obtaining the content of the txt file\n",
    "            with open(txtpath, 'r', encoding='utf-8') as file:\n",
    "                content = file.read()\n",
    "            \n",
    "            # output directory to store the response\n",
    "            outputpath = os.path.join(ouputdir, filename)\n",
    "            \n",
    "            # writing the title for the each txt file\n",
    "            with open(outputpath, 'w', encoding='utf-8') as file:\n",
    "                file.write(f\"Title: {title}\\n\\n{content}\")\n",
    "        else:\n",
    "            print(f\"No matching CSV entry found for {filename}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mistral Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " I am a text-based AI model developed by Mistral AI. While I may exhibit similarities to other models, I was specifically designed and trained by this team. If you'd like more information about me or my capabilities, feel free to ask!\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "    base_url='http://localhost:11434/v1/',\n",
    "\n",
    "    # required but ignored\n",
    "    api_key='ollama',\n",
    ")\n",
    "\n",
    "chat_completion = client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\n",
    "            'role': 'user',\n",
    "            'content': 'Which model are you?',\n",
    "        }\n",
    "    ],\n",
    "    model='mistral',\n",
    ")\n",
    "\n",
    "print(chat_completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__All the files to be passed for summarisation__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary for INQ000350057.txt\n",
      "Summary for INQ000350094.txt\n",
      "Summary for INQ000350513.txt\n",
      "Summary for INQ000350691.txt\n",
      "Summary for INQ000383581.txt\n",
      "Summary for INQ000383585.txt\n",
      "Summary for INQ000383998.txt\n",
      "Summary for INQ000385719.txt\n",
      "Summary for INQ000395589.txt\n",
      "Summary for INQ000395913.txt\n",
      "Summary for INQ000396684.txt\n",
      "Summary for INQ000396685.txt\n",
      "Summary for INQ000396686.txt\n",
      "Summary for INQ000400585.txt\n",
      "Summary for INQ000412042.txt\n",
      "Summaries have been saved successfully.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "\n",
    "\n",
    "client = OpenAI(\n",
    "    base_url='http://localhost:11434/v1/',\n",
    "    api_key='ollama',  # Placeholder, required by the client but not used\n",
    ")\n",
    "\n",
    "# chunking each file text\n",
    "def chunktext(text, chunk_size=3500, overlap=150):\n",
    "    chunks = []\n",
    "    start = 0\n",
    "    while start < len(text):\n",
    "        end = min(start + chunk_size, len(text))\n",
    "        # the last sentence should end with . or ? or !\n",
    "        if end < len(text):\n",
    "            while end > start and text[end] not in '.!?':\n",
    "                end -= 1\n",
    "        chunks.append(text[start:end])\n",
    "        # what should be the next starting point after chunk 1 is passed\n",
    "        # to continue, it should find the word where it cuts off and overlap by 500 so that it will lookup for previous 500 words cut from the specific word\n",
    "        start += chunk_size - overlap\n",
    "    return chunks\n",
    "\n",
    "def getsummary(content):\n",
    "    response = client.chat.completions.create(\n",
    "        model='mistral',\n",
    "        messages=[\n",
    "            {\n",
    "                'role': 'user',\n",
    "                'content': f'Please provide a summary of the following text:\\n\\n{content}',\n",
    "            }\n",
    "        ],\n",
    "        max_tokens=1500,  # Number of tokens for the summary\n",
    "        temperature=0.5,  # Temperature controls the creativity of the response\n",
    "    )\n",
    "    return response.choices[0].message.content+\"\\n\\n\"\n",
    "\n",
    "def summarizetext(filepath):\n",
    "    # reading the file\n",
    "    with open(filepath, 'r', encoding='utf-8') as file:\n",
    "        content = file.read()\n",
    "\n",
    "    chunks = chunktext(content)\n",
    "    \n",
    "    summaries = []\n",
    "    # collecting the summary\n",
    "    for chunk in chunks:\n",
    "        summary = getsummary(chunk)\n",
    "        summaries.append(summary)\n",
    "    \n",
    "    # returning each chunks to file\n",
    "    finalsummary = \"\\n\".join(summaries)\n",
    "    return finalsummary\n",
    "\n",
    "# input directory for reading the cleaned text file\n",
    "inputfiles = '../2.PDFExtraction/PYPDF2/PYPDF2textclean/'\n",
    "# output directory to store the summary of each files\n",
    "outputpath = 'LLM Summaries/Selected_LLM_Models_PYPDF2/mistral/mistralres/'\n",
    "\n",
    "os.makedirs(outputpath, exist_ok=True)\n",
    "\n",
    "for filename in os.listdir(inputfiles):\n",
    "    if filename.endswith('.txt'):\n",
    "        filepath = os.path.join(inputfiles, filename)\n",
    "        \n",
    "        # read and summarize the text content\n",
    "        summary = summarizetext(filepath)\n",
    "        \n",
    "        # write the summary to the output directory\n",
    "        outputfilepath = os.path.join(outputpath, f\"{os.path.splitext(filename)[0]}.txt\")\n",
    "        with open(outputfilepath, 'w', encoding='utf-8') as outputfile:\n",
    "            outputfile.write(summary)\n",
    "        \n",
    "        print(f\"Summary for {filename}\")\n",
    "\n",
    "print(\"Summaries have been saved successfully.\")\n",
    "\n",
    "# rough estimation of 103 minutes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Adding title to the responses in separate directory__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "df = pd.read_csv('../2.PDFExtraction/SamplePdfDetail.csv')\n",
    "\n",
    "txtdir = 'LLM Summaries/Selected_LLM_Models_PYPDF2/mistral/mistralres/'\n",
    "\n",
    "ouputdir = 'LLM Summaries/Selected_LLM_Models_PYPDF2/mistral/mistralfinal/'\n",
    "\n",
    "os.makedirs(ouputdir, exist_ok=True)\n",
    "\n",
    "for filename in os.listdir(txtdir):\n",
    "    if filename.endswith('.txt'):\n",
    "        txtpath = os.path.join(txtdir, filename)\n",
    "        \n",
    "        # replacing the .txt extension with .pdf to match the CSV 'Filename' column\n",
    "        csvfilename = filename.replace('.txt', '.pdf')\n",
    "        \n",
    "        # if the CSV has a matching filename\n",
    "        rowsfound = df[df['Filename'] == csvfilename]\n",
    "        \n",
    "        if not rowsfound.empty:\n",
    "            # row which is appearing as the same filename\n",
    "            title = rowsfound.iloc[0]['Title']\n",
    "            \n",
    "            # obtaining the content of the txt file\n",
    "            with open(txtpath, 'r', encoding='utf-8') as file:\n",
    "                content = file.read()\n",
    "            \n",
    "            # output directory to store the response\n",
    "            outputpath = os.path.join(ouputdir, filename)\n",
    "            \n",
    "            # writing the title for the each txt file\n",
    "            with open(outputpath, 'w', encoding='utf-8') as file:\n",
    "                file.write(f\"Title: {title}\\n\\n{content}\")\n",
    "        else:\n",
    "            print(f\"No matching CSV entry found for {filename}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " I am an artificial intelligence (AI) chatbot, powered by natural language processing and machine learning technologies. My exact model name is specific to the developer who created me, but common AI chatbot models used today might include OpenAI's GPT-2 or GPT-3, Facebook's BART, or T5 developed by Google Research. However, these models may not be the exact one I am using due to proprietary modifications made by my developers.\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "    base_url='http://localhost:11434/v1/',\n",
    "\n",
    "    # required but ignored\n",
    "    api_key='ollama',\n",
    ")\n",
    "\n",
    "chat_completion = client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\n",
    "            'role': 'user',\n",
    "            'content': 'Which model are you?',\n",
    "        }\n",
    "    ],\n",
    "    model='solar',\n",
    ")\n",
    "\n",
    "print(chat_completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__All the files to be passed for summarisation__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary for INQ000350057.txt\n",
      "Summary for INQ000350094.txt\n",
      "Summary for INQ000350513.txt\n",
      "Summary for INQ000350691.txt\n",
      "Summary for INQ000383581.txt\n",
      "Summary for INQ000383585.txt\n",
      "Summary for INQ000383998.txt\n",
      "Summary for INQ000385719.txt\n",
      "Summary for INQ000395589.txt\n",
      "Summary for INQ000395913.txt\n",
      "Summary for INQ000396684.txt\n",
      "Summary for INQ000396685.txt\n",
      "Summary for INQ000396686.txt\n",
      "Summary for INQ000400585.txt\n",
      "Summary for INQ000412042.txt\n",
      "Summaries have been saved successfully.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "\n",
    "# locally hosted server\n",
    "client = OpenAI(\n",
    "    base_url='http://localhost:11434/v1/',\n",
    "    api_key='ollama', \n",
    ")\n",
    "# chunking each file text\n",
    "def chunking(text, chunk_size=3500, overlap=150):\n",
    "    chunks = []\n",
    "    start = 0\n",
    "    while start < len(text):\n",
    "        end = min(start + chunk_size, len(text))\n",
    "        # the last sentence should end with . or ? or !\n",
    "        if end < len(text):\n",
    "            while end > start and text[end] not in '.!?':\n",
    "                end -= 1\n",
    "        chunks.append(text[start:end])\n",
    "        # what should be the next starting point after chunk 1 is passed\n",
    "        # to continue, it should find the word where it cuts off and overlap by 150 so that it will lookup for previous 150 words cut from the current word\n",
    "        start += chunk_size - overlap\n",
    "    return chunks\n",
    "\n",
    "def gensummary(content):\n",
    "    response = client.chat.completions.create(\n",
    "        model='solar',\n",
    "        messages=[\n",
    "            {\n",
    "                'role': 'user',\n",
    "                'content': f'Please provide a summary of the following text:\\n\\n{content}',\n",
    "            }\n",
    "        ],\n",
    "        max_tokens=1500,  # number of tokens\n",
    "        temperature=0.5,  # setting creativity\n",
    "    )\n",
    "    return response.choices[0].message.content+\"\\n\\n\"\n",
    "\n",
    "def summarizetext(filepath):\n",
    "    # reading the file\n",
    "    with open(filepath, 'r', encoding='utf-8') as file:\n",
    "        content = file.read()\n",
    "\n",
    "    # pass the content in chunks\n",
    "    chunks = chunking(content)\n",
    "    \n",
    "    summaries = []\n",
    "    # collecting the summary\n",
    "    for chunk in chunks:\n",
    "        summary = gensummary(chunk)\n",
    "        summaries.append(summary)\n",
    "    \n",
    "    finalsummary = \"\\n\".join(summaries)\n",
    "    return finalsummary\n",
    "\n",
    "# input directory for reading the cleaned text file \n",
    "inputfiles = '../2.PDFExtraction/PYPDF2/PYPDF2textclean/'\n",
    "\n",
    "# output directory to store the summary of each files\n",
    "outputpath = 'LLM Summaries/Selected_LLM_Models_PYPDF2/solar/solarres/'\n",
    "\n",
    "os.makedirs(outputpath, exist_ok=True)\n",
    "\n",
    "for filename in os.listdir(inputfiles):\n",
    "    if filename.endswith('.txt'):\n",
    "        filepath = os.path.join(inputfiles, filename)\n",
    "        \n",
    "        # passing the file for summarizing\n",
    "        summary = summarizetext(filepath)\n",
    "        \n",
    "        # store the summary in the directory\n",
    "        outputfilepath = os.path.join(outputpath, f\"{os.path.splitext(filename)[0]}.txt\")\n",
    "        with open(outputfilepath, 'w', encoding='utf-8') as outputfile:\n",
    "            outputfile.write(summary)\n",
    "        \n",
    "        print(f\"Summary for {filename}\")\n",
    "\n",
    "print(\"Summaries have been saved successfully.\")\n",
    "\n",
    "# rough estimation of 137 minutes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Adding title to the reponses in the separate directory__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "df = pd.read_csv('../2.PDFExtraction/SamplePdfDetail.csv')\n",
    "\n",
    "txtdir = 'LLM Summaries/Selected_LLM_Models_PYPDF2/solar/solarres/'\n",
    "\n",
    "ouputdir = 'LLM Summaries/Selected_LLM_Models_PYPDF2/solar/solarfinal/'\n",
    "\n",
    "os.makedirs(ouputdir, exist_ok=True)\n",
    "\n",
    "for filename in os.listdir(txtdir):\n",
    "    if filename.endswith('.txt'):\n",
    "        txtpath = os.path.join(txtdir, filename)\n",
    "        \n",
    "        # replacing the .txt extension with .pdf to match the CSV 'Filename' column\n",
    "        csvfilename = filename.replace('.txt', '.pdf')\n",
    "        \n",
    "        # if the CSV has a matching filename\n",
    "        rowsfound = df[df['Filename'] == csvfilename]\n",
    "        \n",
    "        if not rowsfound.empty:\n",
    "            # row which is appearing as the same filename\n",
    "            title = rowsfound.iloc[0]['Title']\n",
    "            \n",
    "            # obtaining the content of the txt file\n",
    "            with open(txtpath, 'r', encoding='utf-8') as file:\n",
    "                content = file.read()\n",
    "            \n",
    "            # output directory to store the response\n",
    "            outputpath = os.path.join(ouputdir, filename)\n",
    "            \n",
    "            # writing the title for the each txt file\n",
    "            with open(outputpath, 'w', encoding='utf-8') as file:\n",
    "                file.write(f\"Title: {title}\\n\\n{content}\")\n",
    "        else:\n",
    "            print(f\"No matching CSV entry found for {filename}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Qwen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, I'm an AI language model. How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "    base_url='http://localhost:11434/v1/',\n",
    "\n",
    "    # required but ignored\n",
    "    api_key='ollama',\n",
    ")\n",
    "\n",
    "chat_completion = client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\n",
    "            'role': 'user',\n",
    "            'content': 'Which model are you?',\n",
    "        }\n",
    "    ],\n",
    "    model='qwen',\n",
    ")\n",
    "\n",
    "print(chat_completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__All the files to be passed for summarisation__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary for INQ000350057.txt\n",
      "Summary for INQ000350094.txt\n",
      "Summary for INQ000350513.txt\n",
      "Summary for INQ000350691.txt\n",
      "Summary for INQ000383581.txt\n",
      "Summary for INQ000383585.txt\n",
      "Summary for INQ000383998.txt\n",
      "Summary for INQ000385719.txt\n",
      "Summary for INQ000395589.txt\n",
      "Summary for INQ000395913.txt\n",
      "Summary for INQ000396684.txt\n",
      "Summary for INQ000396685.txt\n",
      "Summary for INQ000396686.txt\n",
      "Summary for INQ000400585.txt\n",
      "Summary for INQ000412042.txt\n",
      "Summaries have been saved successfully.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "\n",
    "\n",
    "client = OpenAI(\n",
    "    base_url='http://localhost:11434/v1/',\n",
    "    api_key='ollama',  # Placeholder, required by the client but not used\n",
    ")\n",
    "\n",
    "# chunking each file text\n",
    "def chunktext(text, chunk_size=3500, overlap=150):\n",
    "    chunks = []\n",
    "    start = 0\n",
    "    while start < len(text):\n",
    "        end = min(start + chunk_size, len(text))\n",
    "        # the last sentence should end with . or ? or !\n",
    "        if end < len(text):\n",
    "            while end > start and text[end] not in '.!?':\n",
    "                end -= 1\n",
    "        chunks.append(text[start:end])\n",
    "        # what should be the next starting point after chunk 1 is passed\n",
    "        # to continue, it should find the word where it cuts off and overlap by 500 so that it will lookup for previous 500 words cut from the specific word\n",
    "        start += chunk_size - overlap\n",
    "    return chunks\n",
    "\n",
    "def getsummary(content):\n",
    "    response = client.chat.completions.create(\n",
    "        model='qwen',\n",
    "        messages=[\n",
    "            {\n",
    "                'role': 'user',\n",
    "                'content': f'Please provide a summary of the following text:\\n\\n{content}',\n",
    "            }\n",
    "        ],\n",
    "        max_tokens=1500,  # Number of tokens for the summary\n",
    "        temperature=0.5,  # Temperature controls the creativity of the response\n",
    "    )\n",
    "    return response.choices[0].message.content+\"\\n\\n\"\n",
    "\n",
    "def summarizetext(filepath):\n",
    "    # reading the file\n",
    "    with open(filepath, 'r', encoding='utf-8') as file:\n",
    "        content = file.read()\n",
    "\n",
    "    chunks = chunktext(content)\n",
    "    \n",
    "    summaries = []\n",
    "    # collecting the summary\n",
    "    for chunk in chunks:\n",
    "        summary = getsummary(chunk)\n",
    "        summaries.append(summary)\n",
    "    \n",
    "    # returning each chunks to file\n",
    "    finalsummary = \"\\n\".join(summaries)\n",
    "    return finalsummary\n",
    "\n",
    "# input directory for reading the cleaned text file\n",
    "inputfiles = '../2.PDFExtraction/PYPDF2/PYPDF2textclean/'\n",
    "# output directory to store the summary of each files\n",
    "outputpath = 'LLM Summaries/Selected_LLM_Models_PYPDF2/qwen/qwenres/'\n",
    "\n",
    "os.makedirs(outputpath, exist_ok=True)\n",
    "\n",
    "for filename in os.listdir(inputfiles):\n",
    "    if filename.endswith('.txt'):\n",
    "        filepath = os.path.join(inputfiles, filename)\n",
    "        \n",
    "        # read and summarize the text content\n",
    "        summary = summarizetext(filepath)\n",
    "        \n",
    "        # write the summary to the output directory\n",
    "        outputfilepath = os.path.join(outputpath, f\"{os.path.splitext(filename)[0]}.txt\")\n",
    "        with open(outputfilepath, 'w', encoding='utf-8') as outputfile:\n",
    "            outputfile.write(summary)\n",
    "        \n",
    "        print(f\"Summary for {filename}\")\n",
    "\n",
    "print(\"Summaries have been saved successfully.\")\n",
    "\n",
    "# rough estimation of 14 minutes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Adding titles for the reponses in the separate directory__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "df = pd.read_csv('../2.PDFExtraction/SamplePdfDetail.csv')\n",
    "\n",
    "txtdir = 'LLM Summaries/Selected_LLM_Models_PYPDF2/qwen/qwenres/'\n",
    "\n",
    "ouputdir = 'LLM Summaries/Selected_LLM_Models_PYPDF2/qwen/qwenfinal/'\n",
    "\n",
    "os.makedirs(ouputdir, exist_ok=True)\n",
    "\n",
    "for filename in os.listdir(txtdir):\n",
    "    if filename.endswith('.txt'):\n",
    "        txtpath = os.path.join(txtdir, filename)\n",
    "        \n",
    "        # replacing the .txt extension with .pdf to match the CSV 'Filename' column\n",
    "        csvfilename = filename.replace('.txt', '.pdf')\n",
    "        \n",
    "        # if the CSV has a matching filename\n",
    "        rowsfound = df[df['Filename'] == csvfilename]\n",
    "        \n",
    "        if not rowsfound.empty:\n",
    "            # row which is appearing as the same filename\n",
    "            title = rowsfound.iloc[0]['Title']\n",
    "            \n",
    "            # obtaining the content of the txt file\n",
    "            with open(txtpath, 'r', encoding='utf-8') as file:\n",
    "                content = file.read()\n",
    "            \n",
    "            # output directory to store the response\n",
    "            outputpath = os.path.join(ouputdir, filename)\n",
    "            \n",
    "            # writing the title for the each txt file\n",
    "            with open(outputpath, 'w', encoding='utf-8') as file:\n",
    "                file.write(f\"Title: {title}\\n\\n{content}\")\n",
    "        else:\n",
    "            print(f\"No matching CSV entry found for {filename}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Xwinlm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As an AI language model, I don't have a specific model or archetype that I am. Instead, I am a general-purpose modeling tool that can be used to generate various types of text based on the input and context provided by users like you. My primary function is to assist with answering questions, providing information, engaging in conversations, and generating creative content like stories or poems.\n",
      "\n",
      "However, my primary architectural structure is a transformer-based neural network, which is a powerful AI model that can process and generating human-like text based on the context it receives from users. The specific architecture of my model varies depending on the context in which I am being used, such as in the case of ChatGPT-4 or GPT-5, which are large-scale language models trained on massive amounts of text data to generate human-like text.\n",
      "\n",
      "Keep in mind that my primary purpose is to assist and interact with users like you, providing information, answering questions, and engaging in conversations. My design allows me to adapt and learn from user interactions, creating a more personalized experience for each user.\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "    base_url='http://localhost:11434/v1/',\n",
    "\n",
    "    # required but ignored\n",
    "    api_key='ollama',\n",
    ")\n",
    "\n",
    "chat_completion = client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\n",
    "            'role': 'user',\n",
    "            'content': 'Which model are you?',\n",
    "        }\n",
    "    ],\n",
    "    model='xwinlm',\n",
    ")\n",
    "\n",
    "print(chat_completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary for INQ000350057.txt\n",
      "Summary for INQ000350094.txt\n",
      "Summary for INQ000350513.txt\n",
      "Summary for INQ000350691.txt\n",
      "Summary for INQ000383581.txt\n",
      "Summary for INQ000383585.txt\n",
      "Summary for INQ000383998.txt\n",
      "Summary for INQ000385719.txt\n",
      "Summary for INQ000395589.txt\n",
      "Summary for INQ000395913.txt\n",
      "Summary for INQ000396684.txt\n",
      "Summary for INQ000396685.txt\n",
      "Summary for INQ000396686.txt\n",
      "Summary for INQ000400585.txt\n",
      "Summary for INQ000412042.txt\n",
      "Summaries have been saved successfully.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "\n",
    "# Initialize the OpenAI client\n",
    "client = OpenAI(\n",
    "    base_url='http://localhost:11434/v1/',\n",
    "    api_key='ollama',  # Placeholder, required by the client but not used\n",
    ")\n",
    "# chunking each file text\n",
    "def chunktext(text, chunk_size=3500, overlap=150):\n",
    "    chunks = []\n",
    "    start = 0\n",
    "    while start < len(text):\n",
    "        end = min(start + chunk_size, len(text))\n",
    "        # the last sentence should end with . or ? or !\n",
    "        if end < len(text):\n",
    "            while end > start and text[end] not in '.!?':\n",
    "                end -= 1\n",
    "        chunks.append(text[start:end])\n",
    "        # what should be the next starting point after chunk 1 is passed\n",
    "        # to continue, it should find the word where it cuts off and overlap by 500 so that it will lookup for previous 500 words cut from the specific word\n",
    "        start += chunk_size - overlap\n",
    "    return chunks\n",
    "\n",
    "def getsummary(content):\n",
    "    response = client.chat.completions.create(\n",
    "        model='xwinlm',\n",
    "        messages=[\n",
    "            {\n",
    "                'role': 'user',\n",
    "                'content': f'Please provide a summary of the following text:\\n\\n{content}',\n",
    "            }\n",
    "        ],\n",
    "        max_tokens=1500,  # Number of tokens for the summary\n",
    "        temperature=0.5,  # Temperature controls the creativity of the response\n",
    "    )\n",
    "    return response.choices[0].message.content+\"\\n\\n\"\n",
    "\n",
    "def summarizetext(filepath):\n",
    "    # reading the file\n",
    "    with open(filepath, 'r', encoding='utf-8') as file:\n",
    "        content = file.read()\n",
    "\n",
    "    chunks = chunktext(content)\n",
    "    \n",
    "    summaries = []\n",
    "    # collecting the summary\n",
    "    for chunk in chunks:\n",
    "        summary = getsummary(chunk)\n",
    "        summaries.append(summary)\n",
    "    \n",
    "    # returning each chunks to file\n",
    "    finalsummary = \"\\n\".join(summaries)\n",
    "    return finalsummary\n",
    "\n",
    "# input directory for reading the cleaned text file\n",
    "inputfiles = '../2.PDFExtraction/PYPDF2/PYPDF2textclean/'\n",
    "# output directory to store the summary of each files\n",
    "outputpath = 'LLM Summaries/Selected_LLM_Models_PYPDF2/xwinlm/xwinlmres/'\n",
    "\n",
    "os.makedirs(outputpath, exist_ok=True)\n",
    "\n",
    "for filename in os.listdir(inputfiles):\n",
    "    if filename.endswith('.txt'):\n",
    "        filepath = os.path.join(inputfiles, filename)\n",
    "        \n",
    "        # read and summarize the text content\n",
    "        summary = summarizetext(filepath)\n",
    "        \n",
    "        # write the summary to the output directory\n",
    "        outputfilepath = os.path.join(outputpath, f\"{os.path.splitext(filename)[0]}.txt\")\n",
    "        with open(outputfilepath, 'w', encoding='utf-8') as outputfile:\n",
    "            outputfile.write(summary)\n",
    "        \n",
    "        print(f\"Summary for {filename}\")\n",
    "\n",
    "print(\"Summaries have been saved successfully.\")\n",
    "\n",
    "# rough estimation of 149 minutes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Adding titles to the responses in the separate directory__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "df = pd.read_csv('../2.PDFExtraction/SamplePdfDetail.csv')\n",
    "\n",
    "txtdir = 'LLM Summaries/Selected_LLM_Models_PYPDF2/xwinlm/xwinlmres/'\n",
    "\n",
    "ouputdir = 'LLM Summaries/Selected_LLM_Models_PYPDF2/xwinlm/xwinlmfinal/'\n",
    "\n",
    "os.makedirs(ouputdir, exist_ok=True)\n",
    "\n",
    "for filename in os.listdir(txtdir):\n",
    "    if filename.endswith('.txt'):\n",
    "        txtpath = os.path.join(txtdir, filename)\n",
    "        \n",
    "        # replacing the .txt extension with .pdf to match the CSV 'Filename' column\n",
    "        csvfilename = filename.replace('.txt', '.pdf')\n",
    "        \n",
    "        # if the CSV has a matching filename\n",
    "        rowsfound = df[df['Filename'] == csvfilename]\n",
    "        \n",
    "        if not rowsfound.empty:\n",
    "            # row which is appearing as the same filename\n",
    "            title = rowsfound.iloc[0]['Title']\n",
    "            \n",
    "            # obtaining the content of the txt file\n",
    "            with open(txtpath, 'r', encoding='utf-8') as file:\n",
    "                content = file.read()\n",
    "            \n",
    "            # output directory to store the response\n",
    "            outputpath = os.path.join(ouputdir, filename)\n",
    "            \n",
    "            # writing the title for the each txt file\n",
    "            with open(outputpath, 'w', encoding='utf-8') as file:\n",
    "                file.write(f\"Title: {title}\\n\\n{content}\")\n",
    "        else:\n",
    "            print(f\"No matching CSV entry found for {filename}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DeepseekLLM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__All the files to be passed for summarisation__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary for INQ000350057.txt\n",
      "Summary for INQ000350094.txt\n",
      "Summary for INQ000350513.txt\n",
      "Summary for INQ000350691.txt\n",
      "Summary for INQ000383581.txt\n",
      "Summary for INQ000383585.txt\n",
      "Summary for INQ000383998.txt\n",
      "Summary for INQ000385719.txt\n",
      "Summary for INQ000395589.txt\n",
      "Summary for INQ000395913.txt\n",
      "Summary for INQ000396684.txt\n",
      "Summary for INQ000396685.txt\n",
      "Summary for INQ000396686.txt\n",
      "Summary for INQ000400585.txt\n",
      "Summary for INQ000412042.txt\n",
      "Summaries have been saved successfully.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "\n",
    "# Initialize the OpenAI client\n",
    "client = OpenAI(\n",
    "    base_url='http://localhost:11434/v1/',\n",
    "    api_key='ollama',  # Placeholder, required by the client but not used\n",
    ")\n",
    "\n",
    "# chunking each file text\n",
    "def chunktext(text, chunk_size=3500, overlap=150):\n",
    "    chunks = []\n",
    "    start = 0\n",
    "    while start < len(text):\n",
    "        end = min(start + chunk_size, len(text))\n",
    "        # the last sentence should end with . or ? or !\n",
    "        if end < len(text):\n",
    "            while end > start and text[end] not in '.!?':\n",
    "                end -= 1\n",
    "        chunks.append(text[start:end])\n",
    "        # what should be the next starting point after chunk 1 is passed\n",
    "        # to continue, it should find the word where it cuts off and overlap by 500 so that it will lookup for previous 500 words cut from the specific word\n",
    "        start += chunk_size - overlap\n",
    "    return chunks\n",
    "\n",
    "def getsummary(content):\n",
    "    response = client.chat.completions.create(\n",
    "        model='deepseek-llm',\n",
    "        messages=[\n",
    "            {\n",
    "                'role': 'user',\n",
    "                'content': f'Please provide a summary of the following text:\\n\\n{content}',\n",
    "            }\n",
    "        ],\n",
    "        max_tokens=1500,  # Number of tokens for the summary\n",
    "        temperature=0.5,  # Temperature controls the creativity of the response\n",
    "    )\n",
    "    return response.choices[0].message.content+\"\\n\\n\"\n",
    "\n",
    "def summarizetext(filepath):\n",
    "    # reading the file\n",
    "    with open(filepath, 'r', encoding='utf-8') as file:\n",
    "        content = file.read()\n",
    "\n",
    "    chunks = chunktext(content)\n",
    "    \n",
    "    summaries = []\n",
    "    # collecting the summary\n",
    "    for chunk in chunks:\n",
    "        summary = getsummary(chunk)\n",
    "        summaries.append(summary)\n",
    "    \n",
    "    # returning each chunks to file\n",
    "    finalsummary = \"\\n\".join(summaries)\n",
    "    return finalsummary\n",
    "\n",
    "# input directory for reading the cleaned text file\n",
    "inputfiles = '../2.PDFExtraction/PYPDF2/PYPDF2textclean/'\n",
    "# output directory to store the summary of each files\n",
    "outputpath = 'LLM Summaries/Selected_LLM_Models_PYPDF2/deepseek-llm/deepseek-llmres/'\n",
    "\n",
    "os.makedirs(outputpath, exist_ok=True)\n",
    "\n",
    "for filename in os.listdir(inputfiles):\n",
    "    if filename.endswith('.txt'):\n",
    "        filepath = os.path.join(inputfiles, filename)\n",
    "        \n",
    "        # read and summarize the text content\n",
    "        summary = summarizetext(filepath)\n",
    "        \n",
    "        # write the summary to the output directory\n",
    "        outputfilepath = os.path.join(outputpath, f\"{os.path.splitext(filename)[0]}.txt\")\n",
    "        with open(outputfilepath, 'w', encoding='utf-8') as outputfile:\n",
    "            outputfile.write(summary)\n",
    "        \n",
    "        print(f\"Summary for {filename}\")\n",
    "\n",
    "print(\"Summaries have been saved successfully.\")\n",
    "\n",
    "# rough estimation of 82  minutes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Adding titles to the responses in the separate directory__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "df = pd.read_csv('../2.PDFExtraction/SamplePdfDetail.csv')\n",
    "\n",
    "txtdir = 'LLM Summaries/Selected_LLM_Models_PYPDF2/deepseek-llm/deepseek-llmres/'\n",
    "\n",
    "ouputdir = 'LLM Summaries/Selected_LLM_Models_PYPDF2/deepseek-llm/deepseek-llmfinal/'\n",
    "\n",
    "os.makedirs(ouputdir, exist_ok=True)\n",
    "\n",
    "for filename in os.listdir(txtdir):\n",
    "    if filename.endswith('.txt'):\n",
    "        txtpath = os.path.join(txtdir, filename)\n",
    "        \n",
    "        # replacing the .txt extension with .pdf to match the CSV 'Filename' column\n",
    "        csvfilename = filename.replace('.txt', '.pdf')\n",
    "        \n",
    "        # if the CSV has a matching filename\n",
    "        rowsfound = df[df['Filename'] == csvfilename]\n",
    "        \n",
    "        if not rowsfound.empty:\n",
    "            # row which is appearing as the same filename\n",
    "            title = rowsfound.iloc[0]['Title']\n",
    "            \n",
    "            # obtaining the content of the txt file\n",
    "            with open(txtpath, 'r', encoding='utf-8') as file:\n",
    "                content = file.read()\n",
    "            \n",
    "            # output directory to store the response\n",
    "            outputpath = os.path.join(ouputdir, filename)\n",
    "            \n",
    "            # writing the title for the each txt file\n",
    "            with open(outputpath, 'w', encoding='utf-8') as file:\n",
    "                file.write(f\"Title: {title}\\n\\n{content}\")\n",
    "        else:\n",
    "            print(f\"No matching CSV entry found for {filename}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding the length of model summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def countchars(dirpath):\n",
    "    # all the files from directory\n",
    "    txtfiles = [f for f in os.listdir(dirpath)]\n",
    "\n",
    "    # altogether total characters in the text file\n",
    "    countchar = 0\n",
    "    for filename in txtfiles:\n",
    "        filepath = os.path.join(dirpath, filename)\n",
    "        with open(filepath, 'r', encoding='utf-8') as file:\n",
    "            countchar += len(file.read())\n",
    "    \n",
    "    return countchar\n",
    "\n",
    "def display(directories):\n",
    "    \n",
    "    dirnames = []\n",
    "    charcount = []\n",
    "\n",
    "    for directory in directories:\n",
    "        # obtaining the names of the directory\n",
    "        dirname = os.path.basename(directory)\n",
    "        \n",
    "        # finding the total character\n",
    "        countchar = countchars(directory)\n",
    "        \n",
    "        # storing the obtained results\n",
    "        dirnames.append(dirname)\n",
    "        charcount.append(countchar)\n",
    "\n",
    "    # sorting based on the character counts\n",
    "    sort = sorted(zip(charcount, dirnames))\n",
    "    charcount, dirnames = zip(*sort)\n",
    "\n",
    "    # visualising the data\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.bar(dirnames, charcount, color='lightgreen', width=0.3)\n",
    "    plt.xlabel('Directory')\n",
    "    plt.ylabel('Total characters')\n",
    "    plt.title('Total character count per Model')\n",
    "    plt.xticks(rotation=45, ha='right')  \n",
    "    plt.show()\n",
    "\n",
    "# list of directories\n",
    "directories = [\n",
    "    '../3.LLM Model/LLM Summaries/Selected_LLM_Models_PYPDF2/gemma/gemmafinal',\n",
    "    '../3.LLM Model/LLM Summaries/Selected_LLM_Models_PYPDF2/deepseek-llm/deepseek-llmfinal',\n",
    "    '../3.LLM Model/LLM Summaries/Selected_LLM_Models_PYPDF2/gemma2/gemma2final',\n",
    "    '../3.LLM Model/LLM Summaries/Selected_LLM_Models_PYPDF2/llama3/llama3final',\n",
    "    '../3.LLM Model/LLM Summaries/Selected_LLM_Models_PYPDF2/llama3.1/llama3.1final',\n",
    "    '../3.LLM Model/LLM Summaries/Selected_LLM_Models_PYPDF2/mistral/mistralfinal',\n",
    "    '../3.LLM Model/LLM Summaries/Selected_LLM_Models_PYPDF2/qwen/qwenfinal',\n",
    "    '../3.LLM Model/LLM Summaries/Selected_LLM_Models_PYPDF2/solar/solarfinal',\n",
    "    '../3.LLM Model/LLM Summaries/Selected_LLM_Models_PYPDF2/xwinlm/xwinlmfinal',\n",
    "]\n",
    "\n",
    "display(directories)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
